{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 17:39:17.665929: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-03 17:39:17.684445: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-03 17:39:18.019613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/birch/anaconda3/envs/p310-rand/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import Tensor\n",
    "import seqio\n",
    "\n",
    "# from Google Research:\n",
    "# https://github.com/google-research/text-to-text-transfer-transformer/blob/84f8bcc14b5f2c03de51bd3587609ba8f6bbd1cd/t5/data/preprocessors.py#L2682\n",
    "def random_spans_noise_mask(\n",
    "  length: int,\n",
    "  noise_density: float,\n",
    "  seeds: Tensor,\n",
    "  mean_noise_span_length=3.0\n",
    ") -> Tensor:\n",
    "  \"\"\"Noise mask consisting of random spans of noise tokens.\n",
    "\n",
    "  The number of noise tokens and the number of noise spans and non-noise spans\n",
    "  are determined deterministically as follows:\n",
    "\n",
    "    num_noise_tokens = round(length * noise_density)\n",
    "    num_nonnoise_spans = num_noise_spans = round(\n",
    "       num_noise_tokens / mean_noise_span_length)\n",
    "\n",
    "  Spans alternate between non-noise and noise, beginning with non-noise.\n",
    "  Subject to the above restrictions, all masks are equally likely.\n",
    "\n",
    "  Args:\n",
    "    length: an int32 scalar (length of the incoming token sequence)\n",
    "    noise_density: a float - approximate density of output mask\n",
    "    seeds: an int32 Tensor, shaped (2, 2)\n",
    "    mean_noise_span_length: a number\n",
    "\n",
    "  Returns:\n",
    "    a boolean tensor with shape [length]\n",
    "  \"\"\"\n",
    "\n",
    "  orig_length = length\n",
    "  # increase length to avoid degeneracy\n",
    "  length = tf.maximum(length, 2)\n",
    "  def to_int(x):\n",
    "    return tf.cast(x, tf.int32)\n",
    "  def to_float(x):\n",
    "    return tf.cast(x, tf.float32)\n",
    "  num_noise_tokens = to_int(tf.round(to_float(length) * noise_density))\n",
    "  # avoid degeneracy by ensuring positive numbers of noise and nonnoise tokens.\n",
    "  num_noise_tokens = tf.minimum(tf.maximum(num_noise_tokens, 1), length - 1)\n",
    "  num_noise_spans = to_int(\n",
    "      tf.round(to_float(num_noise_tokens) / mean_noise_span_length))\n",
    "  # avoid degeneracy by ensuring positive number of noise spans\n",
    "  num_noise_spans = tf.maximum(num_noise_spans, 1)\n",
    "  num_nonnoise_tokens = length - num_noise_tokens\n",
    "  # pick the lengths of the noise spans and the non-noise spans\n",
    "  def _random_segmentation(num_items, num_segments, seed: int):\n",
    "    \"\"\"Partition a sequence of items randomly into non-empty segments.\n",
    "\n",
    "    Args:\n",
    "      num_items: an integer scalar > 0\n",
    "      num_segments: an integer scalar in [1, num_items]\n",
    "      seed: an integer seed\n",
    "    Returns:\n",
    "      a Tensor with shape [num_segments] containing positive integers that add\n",
    "      up to num_items\n",
    "    \"\"\"\n",
    "    first_in_segment = tf.pad(\n",
    "        seqio.stateless_shuffle(\n",
    "            to_int(tf.range(num_items - 1) < num_segments - 1),\n",
    "            seed),\n",
    "        [[1, 0]])\n",
    "    segment_id = tf.cumsum(first_in_segment)\n",
    "    segment_length = tf.math.segment_sum(tf.ones_like(segment_id), segment_id)\n",
    "    return segment_length\n",
    "  noise_span_lengths = _random_segmentation(\n",
    "      num_noise_tokens, num_noise_spans, seeds[0])\n",
    "  nonnoise_span_lengths = _random_segmentation(\n",
    "      num_nonnoise_tokens, num_noise_spans, seeds[1])\n",
    "  interleaved_span_lengths = tf.reshape(\n",
    "      tf.stack([nonnoise_span_lengths, noise_span_lengths], axis=1),\n",
    "      [num_noise_spans * 2])\n",
    "  span_starts = tf.cumsum(interleaved_span_lengths)[:-1]\n",
    "  span_start_indicator = tf.math.unsorted_segment_sum(\n",
    "      tf.ones_like(span_starts), span_starts, length)\n",
    "  span_num = tf.cumsum(span_start_indicator)\n",
    "  is_noise = tf.equal(span_num % 2, 1)\n",
    "  return is_noise[:orig_length]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating 10 noise masks for seq length 30:\n",
      "000000000000000000000000001111\n",
      "000000000000000000000000001111\n",
      "000000000000000000000000001111\n",
      "000000000000000000000000001111\n",
      "000000000000000000000000001111\n",
      "000000000000000000000000001111\n",
      "000000000000000000000000001111\n",
      "000000000000000000000000001111\n",
      "000000000000000000000000001111\n",
      "000000000000000000000000001111\n",
      "generating 10 noise masks for seq length 31:\n",
      "0000000000000000000111100000001\n",
      "0000011110000000000000000000001\n",
      "0000011110000000000000000000001\n",
      "0000000000000010000000000001111\n",
      "0000000000000100000000000001111\n",
      "0000000000000000000000111100001\n",
      "0000000000000000011100000000011\n",
      "0000000111100000000000000000001\n",
      "0000000000111000000000000000011\n",
      "0000000000001000000000000001111\n"
     ]
    }
   ],
   "source": [
    "length=30\n",
    "noise_density=.15\n",
    "mean_noise_span_length=3.\n",
    "attempts=10\n",
    "for length in [30, 31]:\n",
    "  print(f'generating {attempts} noise masks for seq length {length}:')\n",
    "  for _ in range(attempts):\n",
    "    seeds=tf.random.uniform(shape=(2, 2), minval=1, maxval=1024, dtype=tf.int32)\n",
    "    mask: Tensor = random_spans_noise_mask(length=length, noise_density=noise_density, seeds=seeds, mean_noise_span_length=mean_noise_span_length)\n",
    "    print(''.join([str(x) for x in mask.__array__(int)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310-rand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
